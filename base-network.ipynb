{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/qubvel/segmentation_models.pytorch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport time\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport os\nfrom albumentations import *\nfrom albumentations.pytorch import ToTensor\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport segmentation_models_pytorch as smp\nfrom sklearn.model_selection import KFold\nimport tifffile as tiff\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom tqdm import tqdm_notebook as tqdm\nimport gc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nDEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\nNUM_WORKERS = 4\nNUM_EPOCHS = 50\n\nDATA = '../input/hubmap-kidney-segmentation/test/'\nMASKS = '../input/hubmap-256x256/masks'\nTRAIN = '../input/hubmap-256x256/train'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean = np.array([0.65459856,0.48386562,0.69428385])\nstd = np.array([0.15167958,0.23584107,0.13146145])\n\ndef img2tensor(img, dtype:np.dtype=np.float32):\n    if img.ndim==2: \n        img=np.expand_dims(img, 2)\n    img=np.transpose(img, (2, 0, 1))\n    return torch.from_numpy(img.astype(dtype, copy=False))\n\nclass HuBMAPDataset(Dataset):\n    def __init__(self, img_filenames, train=True, tfms=None):\n        self.img_filenames = img_filenames\n        self.train = train\n        self.tfms = tfms\n    \n    def __len__(self):\n        return len(self.img_filenames)\n    \n    def __getitem__(self, idx):\n        fname = self.img_filenames[idx]\n        imgs=cv2.cvtColor(cv2.imread(os.path.join(TRAIN, fname)), cv2.COLOR_BGR2RGB)\n        masks=cv2.imread(os.path.join(MASKS, fname), cv2.IMREAD_GRAYSCALE)\n        if self.tfms is not None:\n            augmented=self.tfms(image=imgs, mask=masks)\n            imgs, masks=augmented['image'], augmented['mask']\n        return img2tensor((imgs/255.0-mean)/std), img2tensor(masks)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_augmentation_train(p=1.0):\n    return Compose([\n        HorizontalFlip(),\n        VerticalFlip(),\n    ], p=p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_loss(pred, target, smooth = 1.):\n    pred = pred.contiguous()\n    target = target.contiguous()\n    inter = (pred*target).sum(dim=2).sum(dim=2)\n\n    loss = (1-((2.0*inter+smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth))) \n    return loss.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_loss(pred, target, bce_weight=0.5):\n    bce = F.binary_cross_entropy_with_logits(pred, target)\n    pred = F.sigmoid(pred)\n\n    dice = dice_loss(pred, target)\n\n    loss = bce * bce_weight + dice * (1 - bce_weight)\n    \n    return loss.to(DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def UnetDenseNet():\n    return smp.Unet(\n    encoder_name='densenet201',\n    encoder_weights='imagenet',\n    in_channels=3,\n    classes=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_filenames = os.listdir(TRAIN)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset_filenames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_filenames[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(42)\nrandom.shuffle(dataset_filenames)\n\ntrain_filenames = dataset_filenames[:7664]\nvalid_filenames = dataset_filenames[7664:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, dataloader_train, dataloader_valid, optimizer):\n    #training phase\n    model.train()\n    train_loss = 0\n    for i, (imgs, masks) in enumerate(dataloader_train):\n        imgs = imgs.to(DEVICE)\n        masks = masks.to(DEVICE)\n        #forward pass\n        outputs = model(imgs)\n        #cal loss and backward\n        loss = calc_loss(outputs, masks)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n    train_loss /= len(dataloader_train)\n    \n    #validating phase\n    model.eval()\n    valid_loss = 0\n    with torch.no_grad():\n        for i, (imgs, masks) in enumerate(dataloader_valid):\n            imgs = imgs.to(DEVICE)\n            masks = masks.to(DEVICE)\n            outputs = model(imgs)\n            loss = calc_loss(outputs, masks)\n            valid_loss += loss.item()\n    valid_loss /=len(dataloader_valid)\n    print(f'EPOCH: {epoch + 1} - train loss: {train_loss} -  valid_loss: {valid_loss}')\n    return train_loss, valid_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_valid_loss = 0\nds_t = HuBMAPDataset(train_filenames, train=True, tfms=get_augmentation_train())\nds_v = HuBMAPDataset(valid_filenames, train=False)\ndataloader_t = torch.utils.data.DataLoader(ds_t, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\ndataloader_v = torch.utils.data.DataLoader(ds_v, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\nmodel =  UnetDenseNet().to(DEVICE)\noptimizer = torch.optim.Adam([\n    {'params': model.parameters(), 'lr': 1e-3},\n])\n\ntrain_loss = 0\nvalid_loss = 0\n\nfor epoch in tqdm(range(NUM_EPOCHS)):\n    train_loss, valid_loss = train_one_epoch(model, dataloader_t, dataloader_v, optimizer)\n    if best_valid_loss == 0:\n        best_valid_loss = valid_loss\n    if best_valid_loss >= valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model, 'best_unet_model.pth')\n\n    gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}