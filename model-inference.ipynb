{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/packages/pretrainedmodels-0.7.4-py3-none-any.whl\n!pip install ../input/segmentationmodelspytorch/segmentation_models/timm-0.1.20-py3-none-any.whl\n!pip install ../input/packages/efficientnet_pytorch-0.6.3-py2.py3-none-any.whl\n!pip install ../input/segmentationmodelspytorch/segmentation_models/segmentation_models_pytorch-0.1.2-py3-none-any.whl","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/packages/pretrainedmodels-0.7.4-py3-none-any.whl\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (1.7.0)\nRequirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (2.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (4.59.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (0.8.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4) (1.15.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels==0.7.4) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels==0.7.4) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels==0.7.4) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels==0.7.4) (1.19.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels==0.7.4) (7.2.0)\nInstalling collected packages: pretrainedmodels\nSuccessfully installed pretrainedmodels-0.7.4\nProcessing /kaggle/input/segmentationmodelspytorch/segmentation_models/timm-0.1.20-py3-none-any.whl\nRequirement already satisfied: torch>=1.0 in /opt/conda/lib/python3.7/site-packages (from timm==0.1.20) (1.7.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.1.20) (0.8.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm==0.1.20) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm==0.1.20) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm==0.1.20) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm==0.1.20) (1.19.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.1.20) (7.2.0)\nInstalling collected packages: timm\nSuccessfully installed timm-0.1.20\nProcessing /kaggle/input/packages/efficientnet_pytorch-0.6.3-py2.py3-none-any.whl\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3) (1.7.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3) (1.19.5)\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.6.3\nProcessing /kaggle/input/segmentationmodelspytorch/segmentation_models/segmentation_models_pytorch-0.1.2-py3-none-any.whl\nRequirement already satisfied: torchvision>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.1.2) (0.8.1)\nRequirement already satisfied: efficientnet-pytorch==0.6.3 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.1.2) (0.6.3)\nRequirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.1.2) (0.7.4)\nRequirement already satisfied: timm==0.1.20 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.1.2) (0.1.20)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.2) (1.7.0)\nRequirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.2) (2.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.2) (4.59.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.2) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.2) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.2) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.1.2) (1.19.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.3.0->segmentation-models-pytorch==0.1.2) (7.2.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.2) (1.15.0)\nInstalling collected packages: segmentation-models-pytorch\nSuccessfully installed segmentation-models-pytorch-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/hubmap-kidney-segmentation/sample_submission.csv\n/kaggle/input/hubmap-kidney-segmentation/HuBMAP-20-dataset_information.csv\n/kaggle/input/hubmap-kidney-segmentation/train.csv\n/kaggle/input/hubmap-kidney-segmentation/test/aa05346ff.tiff\n/kaggle/input/hubmap-kidney-segmentation/test/sample_submission.csv\n/kaggle/input/hubmap-kidney-segmentation/test/3589adb90-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/test/2ec3f1bb9.tiff\n/kaggle/input/hubmap-kidney-segmentation/test/3589adb90.tiff\n/kaggle/input/hubmap-kidney-segmentation/test/d488c759a-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/test/57512b7f1-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/test/d488c759a.tiff\n/kaggle/input/hubmap-kidney-segmentation/test/57512b7f1.tiff\n/kaggle/input/hubmap-kidney-segmentation/test/aa05346ff-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/test/2ec3f1bb9-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/0486052bb-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/4ef6695ce-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/e79de561c-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/095bf7a1f.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/0486052bb.json\n/kaggle/input/hubmap-kidney-segmentation/train/095bf7a1f-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/b9a3865fc.json\n/kaggle/input/hubmap-kidney-segmentation/train/26dc41664.json\n/kaggle/input/hubmap-kidney-segmentation/train/afa5e8098.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/e79de561c.json\n/kaggle/input/hubmap-kidney-segmentation/train/8242609fa-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/e79de561c.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/4ef6695ce.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/cb2d976f4-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/0486052bb.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/b9a3865fc-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/aaa6a05cc.json\n/kaggle/input/hubmap-kidney-segmentation/train/b9a3865fc.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/aaa6a05cc.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/2f6ecfcdf-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/2f6ecfcdf.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/afa5e8098-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/54f2eec69.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/8242609fa.json\n/kaggle/input/hubmap-kidney-segmentation/train/4ef6695ce.json\n/kaggle/input/hubmap-kidney-segmentation/train/c68fe75ea.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/54f2eec69.json\n/kaggle/input/hubmap-kidney-segmentation/train/cb2d976f4.json\n/kaggle/input/hubmap-kidney-segmentation/train/1e2425f28.json\n/kaggle/input/hubmap-kidney-segmentation/train/26dc41664-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/8242609fa.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/afa5e8098.json\n/kaggle/input/hubmap-kidney-segmentation/train/1e2425f28.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/c68fe75ea-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/b2dc8411c-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/b2dc8411c.json\n/kaggle/input/hubmap-kidney-segmentation/train/1e2425f28-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/c68fe75ea.json\n/kaggle/input/hubmap-kidney-segmentation/train/b2dc8411c.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/54f2eec69-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/cb2d976f4.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/aaa6a05cc-anatomical-structure.json\n/kaggle/input/hubmap-kidney-segmentation/train/095bf7a1f.json\n/kaggle/input/hubmap-kidney-segmentation/train/26dc41664.tiff\n/kaggle/input/hubmap-kidney-segmentation/train/2f6ecfcdf.json\n/kaggle/input/base-network/best_unet_model.pth\n/kaggle/input/base-network/__results__.html\n/kaggle/input/base-network/__notebook__.ipynb\n/kaggle/input/base-network/__output__.json\n/kaggle/input/base-network/custom.css\n/kaggle/input/segmentationmodelspytorch/segmentation_models/tqdm-4.52.0-py2.py3-none-any.whl\n/kaggle/input/segmentationmodelspytorch/segmentation_models/timm-0.2.1-py3-none-any.whl\n/kaggle/input/segmentationmodelspytorch/segmentation_models/dataclasses-0.6-py3-none-any.whl\n/kaggle/input/segmentationmodelspytorch/segmentation_models/six-1.15.0-py2.py3-none-any.whl\n/kaggle/input/segmentationmodelspytorch/segmentation_models/pretrainedmodels-0.7.4.xyz\n/kaggle/input/segmentationmodelspytorch/segmentation_models/Pillow-8.0.1-cp37-cp37m-manylinux1_x86_64.whl\n/kaggle/input/segmentationmodelspytorch/segmentation_models/numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl\n/kaggle/input/segmentationmodelspytorch/segmentation_models/torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl\n/kaggle/input/segmentationmodelspytorch/segmentation_models/munch-2.5.0-py2.py3-none-any.whl\n/kaggle/input/segmentationmodelspytorch/segmentation_models/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl\n/kaggle/input/segmentationmodelspytorch/segmentation_models/timm-0.1.20-py3-none-any.whl\n/kaggle/input/segmentationmodelspytorch/segmentation_models/segmentation-models-pytorch-0.1.2.xyz\n/kaggle/input/segmentationmodelspytorch/segmentation_models/efficientnet_pytorch-0.6.3.xyz\n/kaggle/input/segmentationmodelspytorch/segmentation_models/typing_extensions-3.7.4.3-py3-none-any.whl\n/kaggle/input/segmentationmodelspytorch/segmentation_models/future-0.18.2.xyz\n/kaggle/input/segmentationmodelspytorch/segmentation_models/segmentation_models_pytorch-0.1.2-py3-none-any.whl\n/kaggle/input/packages/efficientnet-1.1.0-py3-none-any.whl\n/kaggle/input/packages/pretrainedmodels-0.7.4-py3-none-any.whl\n/kaggle/input/packages/efficientnet_pytorch-0.6.3-py2.py3-none-any.whl\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport time\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport os\nfrom albumentations import *\nfrom albumentations.pytorch import ToTensor\nimport cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport segmentation_models_pytorch as smp\nfrom sklearn.model_selection import KFold\nimport tifffile as tiff\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom tqdm import tqdm_notebook as tqdm\nimport gc\n","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def UnetDenseNet():\n    return smp.Unet(\n    encoder_name='densenet201',\n    encoder_weights=None,\n    in_channels=3,\n    classes=1)","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model = UnetDenseNet().cuda()","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = torch.load('../input/base-network/best_unet_model.pth')","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"22"},"metadata":{}}]},{"cell_type":"code","source":"#test open file","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/hubmap-kidney-segmentation/sample_submission.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"          id  predicted\n0  2ec3f1bb9        NaN\n1  3589adb90        NaN\n2  d488c759a        NaN\n3  aa05346ff        NaN\n4  57512b7f1        NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2ec3f1bb9</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3589adb90</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>d488c759a</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aa05346ff</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57512b7f1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"fold = 0\nnfolds = 5\nreduce = 4\nsz = 256\n\nBATCH_SIZE = 16\nDEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\nNUM_WORKERS = 4\nSEED = 2020\nTH = 0.50  #threshold for positive predictions\n\nDATA = '../input/hubmap-kidney-segmentation/test/'\nLABELS = '../input/hubmap-kidney-segmentation/train.csv'","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/iafoss/256x256-images\nmean = np.array([0.63701495, 0.4709702,  0.6817423] )\nstd = np.array([0.15978882, 0.2245109, 0.14173926])\n\ndef img2tensor(img,dtype:np.dtype=np.float32):\n    if img.ndim==2 : img = np.expand_dims(img,2)\n    img = np.transpose(img,(2,0,1))\n    return torch.from_numpy(img.astype(dtype, copy=False))\n\nclass HuBMAPTestDataset(Dataset):\n    def __init__(self, idx, sz=sz, reduce=reduce):\n        self.data = rasterio.open(os.path.join(DATA,idx+'.tiff'), transform = identity,\n                                 num_threads='all_cpus')\n        # some images have issues with their format \n        # and must be saved correctly before reading with rasterio\n        if self.data.count != 3:\n            subdatasets = self.data.subdatasets\n            self.layers = []\n            if len(subdatasets) > 0:\n                for i, subdataset in enumerate(subdatasets, 0):\n                    self.layers.append(rasterio.open(subdataset))\n        self.shape = self.data.shape\n        self.reduce = reduce\n        self.sz = reduce*sz\n        self.pad0 = (self.sz - self.shape[0]%self.sz)%self.sz\n        self.pad1 = (self.sz - self.shape[1]%self.sz)%self.sz\n        self.n0max = (self.shape[0] + self.pad0)//self.sz\n        self.n1max = (self.shape[1] + self.pad1)//self.sz\n        \n    def __len__(self):\n        return self.n0max*self.n1max\n    \n    def __getitem__(self, idx):\n        # the code below may be a little bit difficult to understand,\n        # but the thing it does is mapping the original image to\n        # tiles created with adding padding, as done in\n        # https://www.kaggle.com/iafoss/256x256-images ,\n        # and then the tiles are loaded with rasterio\n        # n0,n1 - are the x and y index of the tile (idx = n0*self.n1max + n1)\n        n0,n1 = idx//self.n1max, idx%self.n1max\n        # x0,y0 - are the coordinates of the lower left corner of the tile in the image\n        # negative numbers correspond to padding (which must not be loaded)\n        x0,y0 = -self.pad0//2 + n0*self.sz, -self.pad1//2 + n1*self.sz\n        # make sure that the region to read is within the image\n        p00,p01 = max(0,x0), min(x0+self.sz,self.shape[0])\n        p10,p11 = max(0,y0), min(y0+self.sz,self.shape[1])\n        img = np.zeros((self.sz,self.sz,3),np.uint8)\n        # mapping the loade region to the tile\n        if self.data.count == 3:\n            img[(p00-x0):(p01-x0),(p10-y0):(p11-y0)] = np.moveaxis(self.data.read([1,2,3],\n                window=Window.from_slices((p00,p01),(p10,p11))), 0, -1)\n        else:\n            for i,layer in enumerate(self.layers):\n                img[(p00-x0):(p01-x0),(p10-y0):(p11-y0),i] =\\\n                  layer.read(1,window=Window.from_slices((p00,p01),(p10,p11)))\n        \n        if self.reduce != 1:\n            img = cv2.resize(img,(self.sz//reduce,self.sz//reduce),\n                             interpolation = cv2.INTER_AREA)\n        #check for empty imges\n        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n        h,s,v = cv2.split(hsv)\n        if (s>s_th).sum() <= p_th or img.sum() <= p_th:\n            #images with -1 will be skipped\n            return img2tensor((img/255.0 - mean)/std), -1\n        else: return img2tensor((img/255.0 - mean)/std), idx","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/bguberfain/memory-aware-rle-encoding\n#with bug fix\ndef rle_encode_less_memory(img):\n    #watch out for the bug\n    pixels = img.T.flatten()\n    \n    # This simplified method requires first and last pixel to be zero\n    pixels[0] = 0\n    pixels[-1] = 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] -= runs[::2]\n    \n    return ' '.join(str(x) for x in runs)","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#iterator like wrapper that returns predicted masks\nclass Model_pred:\n    def __init__(self, models, dl, tta:bool=True, half:bool=False):\n        self.models = models\n        self.dl = dl\n        self.tta = tta\n        self.half = half\n        \n    def __iter__(self):\n        count=0\n        with torch.no_grad():\n            for x,y in iter(self.dl):\n                if ((y>=0).sum() > 0): #exclude empty images\n                    x = x[y>=0].to(DEVICE)\n                    y = y[y>=0]\n                    if self.half: x = x.half()\n                    py = None\n                    for model in self.models:\n                        p = model(x)\n                        p = torch.sigmoid(p).detach()\n                        if py is None: py = p\n                        else: py += p\n                    if self.tta:\n                        #x,y,xy flips as TTA\n                        flips = [[-1],[-2],[-2,-1]]\n                        for f in flips:\n                            xf = torch.flip(x,f)\n                            for model in self.models:\n                                p = model(xf)\n                                p = torch.flip(p,f)\n                                py += torch.sigmoid(p).detach()\n                        py /= (1+len(flips))        \n                    py /= len(self.models)\n\n                    py = F.upsample(py, scale_factor=reduce, mode=\"bilinear\")\n                    py = py.permute(0,2,3,1).float().cpu()\n                    \n                    batch_size = len(py)\n                    for i in range(batch_size):\n                        yield py[i],y[i]\n                        count += 1\n                    \n    def __len__(self):\n        return len(self.dl.dataset)","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"models = [model]","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import rasterio\nfrom rasterio.windows import Window","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"26"},"metadata":{}}]},{"cell_type":"code","source":"s_th = 40  #saturation blancking threshold\np_th = 1000*(sz//256)**2 #threshold for the minimum number of pixels\nidentity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n\nnames,preds = [],[]\nprint(df)\nfor idx,row in tqdm(df.iterrows(),total=len(df)):\n    idx = row['id']\n    ds = HuBMAPTestDataset(idx)\n    #rasterio cannot be used with multiple workers\n    dl = DataLoader(ds,BATCH_SIZE,num_workers=0,shuffle=False,pin_memory=True)\n    mp = Model_pred(models,dl)\n    #generate masks\n    mask = torch.zeros(len(ds),ds.sz,ds.sz,dtype=torch.int8)\n    for p,i in iter(mp): mask[i.item()] = p.squeeze(-1) > TH\n    \n    #reshape tiled masks into a single mask and crop padding\n    mask = mask.view(ds.n0max,ds.n1max,ds.sz,ds.sz).\\\n        permute(0,2,1,3).reshape(ds.n0max*ds.sz,ds.n1max*ds.sz)\n    mask = mask[ds.pad0//2:-(ds.pad0-ds.pad0//2) if ds.pad0 > 0 else ds.n0max*ds.sz,\n        ds.pad1//2:-(ds.pad1-ds.pad1//2) if ds.pad1 > 0 else ds.n1max*ds.sz]\n    \n    #convert to rle\n    #https://www.kaggle.com/bguberfain/memory-aware-rle-encoding\n    rle = rle_encode_less_memory(mask.numpy())\n    names.append(idx)\n    preds.append(rle)\n    del mask, ds, dl\n    gc.collect()","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"          id  predicted\n0  2ec3f1bb9        NaN\n1  3589adb90        NaN\n2  d488c759a        NaN\n3  aa05346ff        NaN\n4  57512b7f1        NaN\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ad3793756ef4d7a9e6beb44fb47236f"}},"metadata":{}}]},{"cell_type":"code","source":"df = pd.DataFrame({'id':names,'predicted':preds})\ndf.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"          id                                          predicted\n0  2ec3f1bb9  60642347 2 60666327 27 60690310 46 60714292 63...\n1  3589adb90  68570660 14 68600088 23 68629517 31 68658947 3...\n2  d488c759a  271721609 9 271768267 12 271814926 14 27186158...\n3  aa05346ff  53041035 13 53071746 27 53102462 35 53133178 4...\n4  57512b7f1  279956105 3 279989338 15 280022576 20 28005581...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2ec3f1bb9</td>\n      <td>60642347 2 60666327 27 60690310 46 60714292 63...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3589adb90</td>\n      <td>68570660 14 68600088 23 68629517 31 68658947 3...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>d488c759a</td>\n      <td>271721609 9 271768267 12 271814926 14 27186158...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aa05346ff</td>\n      <td>53041035 13 53071746 27 53102462 35 53133178 4...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57512b7f1</td>\n      <td>279956105 3 279989338 15 280022576 20 28005581...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}